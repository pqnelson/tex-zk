% 35
\begin{node}\label{prop-0000}%
I'm following Mendelson's treatment~\cite{mendelson2015mathematical} of
propositional logic, with heavy correctives from
Harrison~\cite{harrison2009handbook}. Propositional logic deals with
only logical objects (``propositions''). Classical propositional logic
has propositions be either true or false, depending on the valuation of
the propositional variables and the logical connectives involved in the
proposition.
\end{node}

\begin{node}\label{prop-000H}%
We can divide the study of propositional logic into two parts: its
syntax and its semantics. The syntax of propositional logic amounts to
introducing its formal grammar and its informal interpretation, whereas
the semantics amounts to writing down truth tables.

This division into syntax and semantics survives when we study
first-order logic, and (ostensibly) any other formal system.
\end{node}

\begin{node}[Syntax]\label{prop-000J}%
\begin{node}\label{prop-000I}%
The BNF grammar for propositional logic may be written down explicitly
as a half-dozen production rules with variables treated as a
``primitive''. These rules tell us that variables are propositions,
so are negations of propositions, conjunction, disjunction, implication,
and bi-implication of propositions form propositions (respectively).
\begin{center}
\begin{tabular}{rcl}
$\langle$\textit{proposition}$\rangle$ & ::= & $\langle$\textit{variable}$\rangle$\\
& $|$ & $\neg\langle$\textit{proposition}$\rangle$\\
& $|$ & $\langle$\textit{proposition}$\rangle\land\langle$\textit{proposition}$\rangle$\\
& $|$ & $\langle$\textit{proposition}$\rangle\lor\langle$\textit{proposition}$\rangle$\\
& $|$ & $\langle$\textit{proposition}$\rangle\implies\langle$\textit{proposition}$\rangle$\\
& $|$ & $\langle$\textit{proposition}$\rangle\iff\langle$\textit{proposition}$\rangle$\\
\end{tabular}
\end{center}
\end{node}

\begin{definition}\label{prop-0002}%
Let $V$ be a (nonempty, countably infinite) set of propositional variables. Then
we inductively define a \define{Proposition} according to the following
rules:
\begin{enumerate}
\item Any propositional variable $A\in V$ is a proposition;
\item If $A$ and $B$ are propositions, then so are $\neg A$, $A\land B$,
  $A\lor B$, $A\implies B$, and $A\iff B$.
\end{enumerate}
Only those expressions constructed by these rules are propositions.

\begin{node}\label{prop-0003}%
We usually keep the set of variables $V$ implicit throughout. So we will
not explicitly refer to it unless absolutely necessary. We will
understand that ``a proposition'' really means ``a proposition over the
set of propositional variables $V$'', and we keep it in the back of our minds.
\end{node}

\begin{node}\label{prop-000G}%
We can encode the syntax of propositional logic using \SML\ as a
recursive data structure. This reflects the tree-like structure to the
grammar of well-formed formulas \zref{prop-000I}.

If we were to do this in production, we would probably place this in a
structure with the various other utility functions.

\begin{sml}
datatype Prop = Atom of string
              | Not of Prop
              | And of Prop * Prop
              | Or of Prop * Prop
              | Implies of Prop * Prop
              | Iff of Prop * Prop;
\end{sml}
\end{node}
\end{definition}

\begin{node}[Precedence]\label{prop-000D}%
We should note that logical connectives have the following binding
strength (from weakest to strongest): $\neg$, $\land$, $\lor$,
$\implies$, $\iff$. These are ``left associative''. We may insert
parentheses to alter it. Some examples:
\begin{enumerate}
\item $A\iff (\neg B)\lor C\implies D$ is parsed as $A\iff(((\neg B)\lor C)\implies D)$.
\item $A\implies B\implies C$ is parsed as $(A\implies B)\implies C$.
\end{enumerate}
\end{node}
\end{node}

\begin{node}[Semantics]\label{prop-000K}%
\begin{node}[Connectives]\label{prop-0001}%
  The usual connectives are enumerated. We begin with negation.
\begin{enumerate}
\item If $A$ is
a proposition, then its \define{negation} is denoted $\neg A$. Its truth table is
\[\begin{array}{c|c}
A & \neg A\\ \hline
\verum & \falsum\\
\falsum & \verum\\
\end{array}\]
where $\verum$ and $\falsum$ are the truth values ``true'' and
``false'', respectively.
\item Let $A$ and $B$ be propositions. Their \define{conjunction} is the
  proposition denoted $A\land B$ with truth table
\[\begin{array}{cc|c}
A & B & A\land B\\\hline
\verum  & \verum  & \verum\\
\falsum & \verum  & \falsum\\
\verum  & \falsum & \falsum\\
\falsum & \falsum & \falsum\\
\end{array}\]
We refer to the subpropositions $A$ and $B$ as \define{Conjuncts} of
$A\land B$.
\item Let $A$ and $B$ be propositions. Their \define{Disjunction} is the
  proposition denoted $A\lor B$ and is interpreted as ``Either $A$ or
  $B$ or both''. Its truth table is
\[\begin{array}{cc|c}
A & B & A\lor B\\\hline
\verum  & \verum  & \verum\\
\falsum & \verum  & \verum\\
\verum  & \falsum & \verum\\
\falsum & \falsum & \falsum\\
\end{array}\]
Observe $A\lor B$ is false only when both $A$ and $B$ are false.
The subpropositions $A$ and $B$ are called the \define{Disjuncts} of
$A\lor B$.
\item The conditional ``If $A$, then $B$'' requires some
  justification. Surely ``If $\verum$, then $\falsum$'' should be
  false. But what of the other three possible cases? We should hope ``If
  $\verum$, then $\verum$'' is true. We will adopt the convention that
  ``If $\falsum$, then $B$'' is always true. The truth table may be
  written down as
\[\begin{array}{cc|c}
A & B & A\implies B\\\hline
\verum  & \verum  & \verum\\
\falsum & \verum  & \verum\\
\verum  & \falsum & \falsum\\
\falsum & \falsum & \verum\\
\end{array}\]
We call the subformula $A$ the \define{Antecedent} and the subformula
$B$ the \define{Consequent} (or sometimes \textit{Succedent}) of the
formula $A\implies B$.

\textsc{Caution:} The implication should not be used when considering
counterfactuals or causal laws. As odd as it sounds, neither
counterfactuals nor causal laws are needed in mathematics.
\item Let $A$ and $B$ be propositions. The logical equivalence of $A$
  and $B$, or \define{Biconditional} of $A$ and $B$, is the proposition
  denoted $A\iff B$ and is true only when $A$ and $B$ have the same
  truth values:
\[\begin{array}{cc|c}
A & B & A\iff B\\\hline
\verum  & \verum  & \verum\\
\falsum & \verum  & \falsum\\
\verum  & \falsum & \falsum\\
\falsum & \falsum & \verum\\
\end{array}\]
\end{enumerate}
\end{node}

\begin{node}\label{prop-0004}%
Let $V$ be our set of variables. A \define{Valuation} (or
\textit{Truth Function}) is a function $\rho\colon V\to\{\verum,\falsum\}$
assigning a truth value to each propositional variable. Intuitively,
this corresponds to a row in the truth table.

We will abuse notation and write $\rho(A)$ for any proposition $A$ over
the propositional variables $V$, and understand this to mean it is the
result of looking at the relevant row of the truth table for $A$.

Valuations describe the \emph{semantics} of logic, in the sense
that we are describing a possible configuration of the ``world''.
\end{node}

\begin{definition}\label{prop-000L}%
We call a proposition $A$ a \define{Tautology} (or \textit{Logically Valid})
if it evaluates to $\verum$ under every valuation $\rho(A)=\verum$.
That is to say, its truth-table value is ``true'' for \emph{all} rows.

``Validity'' is the term used in first-order logic, but Wittgenstein's
\textit{Tractatus} popularized the term ``Tautology''.
\end{definition}

\begin{definition}\label{prop-000M}%
We will call a proposition $A$ \define{Satisfiable} if there exists at
least one valuation $\rho$ for which $\rho(A)=\verum$. 

\begin{node}\label{prop-000N}%
All tautologies are also satisfiable.
\end{node}
\end{definition}

\begin{definition}\label{prop-0005}%
We say a proposition $C$ is a \define{Logical Consequence} of
proposition $B$ if every valuation $\rho$ for which $\rho(B)$ is true
also makes $\rho(C)$ true.
\end{definition}

\begin{definition}\label{prop-0006}%
Let $B$ and $C$ be propositions. We will say $B$ and $C$ are
\define{Logically Equivalent} if for every valuation $\rho$ the
truth value of $\rho(B)$ is identical to the truth value of $\rho(C)$.
\end{definition}

\begin{node}\label{prop-0007}%
Let $B$ and $C$ be propositions.
\begin{enumerate}
\item $C$ is a logical consequence of $B$ if and only if $B\implies C$
  is a tautology;
\item $B$ and $C$ are logically equivalent if and only if $B\iff C$ is a tautology.
\end{enumerate}
\end{node}

\begin{definition}\label{prop-0008}%
We will call a proposition a \define{Contradiction} if there is no
valuation for which it is true. Equivalently, if a proposition is
false under every valuation, then it is a contradiction.
\begin{node}\label{prop-0009}%
Observe, a proposition $A$ is a contradiction if and only if $\neg A$
is a tautology.
\end{node}
\end{definition}

\begin{node}\label{prop-000A}%
Let $\tau(x_{1},\dots,x_{n})$ be a tautology involving the $n$
metavariables $x_{1}$, \dots, $x_{n}$ ranging over propositions. Let
$A_{1}$, \dots, $A_{n}$ be any $n$ propositions. Then $\tau(A_{1},\dots,
A_{n})$ is a tautology, which Mendelson calls \textit{Logically True}.

Conversely, given any contradiction $\gamma(x_{1},\dots, x_{m})$
parametrized by $m$ metavariables $x_{1}$, \dots, $x_{m}$ ranging over
propositions, and given any $m$ propositions $B_{1}$, \dots, $B_{m}$, we
see that $\gamma(B_{1},\dots,B_{m})$ is a contradiction (which Mendelson
calls \textit{Logically False}).
\end{node}

\begin{node}\label{prop-000B}%
Let $B$ and $C$ be propositions.
If both $B$ and $B\implies C$ are tautologies, then so is $C$.
\end{node}

\begin{node}\label{prop-000C}%
Let $A(x)$ be a proposition parametrized by a metavariable $x$ ranging
over propositions.
Let $B$ and $C$ be propositions. Then $(B\iff C)\implies(A(B)\iff A(C))$
is a tautology.
\end{node}

\begin{node}[Adequate sets of connectives]\label{prop-000E}%
Every proposition is logically equivalent to a proposition involving the
connectives $\neg$, $\land$, $\lor$. That is to say, the set of
connectives $\{\neg,\land,\lor\}$ is adequate for propositional logic
and the others may be expressed in terms of them.

Furthermore, the sets $\{\neg,\land\}$, $\{\neg,\lor\}$, and $\{\neg,\implies\}$
are adequate for propositional logic (in the sense that any proposition
is logically equivalent to one involving only these connectives). This
is because $A\land B$ is logically equivalent to $\neg(\neg A\lor\neg B)$,
$A\implies B$ is logically equivalent to $(\neg A)\lor B$, and $A\iff B$
is logically equivalent to $(A\implies B)\land(B\implies A)$.
\end{node}
\end{node}

\begin{node}[Axiomatic System]\label{prop-000F}%
Mendelson~\cite[\S1.4]{mendelson2015mathematical} offers a so-called
``axiomatic system'' for propositional logic. It's a Hilbert proof
calculus, using implication $(\implies)$ and negation $(\neg)$ as the
primitive connectives, with a handful of axioms and only
\textit{modus ponens} as its rule of inference. More importantly, this
gives us a \emph{purely syntactic notion of proof} independent of
valuations and truth tables. We can prove that every theorem proven
by this system is a tautology, and vice-versa. In particular, Mendelson
proves the deduction theorem, the completeness theorem, and the consistency of
propositional logic.
\end{node}

\begin{node}[Normal forms]\label{prop-000P}%
A common trick in logic is to take some sort of ``normal form'' of
formulas. That is to say, we restrict attention to a sublanguage of
propositional logic such that (a) it is constructed using an adequate
set of connectives~\zref{prop-000E}, and (b) it simplifies proving if a
proposition is satisfiable or unsatisfiable. (This is far too applied a
topic for Mendelson~\cite{mendelson2015mathematical}, and I am relying on
Harrison~\cite{harrison2009handbook} for much of the material here.)

\begin{definition}\label{prop-000Q}%
In propositional logic, we define a \define{Literal} to be a
propositional variable or its negation. We say that a literal is
\define{Negative} if it is of the form $\neg A$; otherwise we say it is
\define{Positive}. 
\end{definition}

\begin{definition}\label{prop-000O}%
We say a proposition is in \define{Negation Normal Form} if it is
constructed using conjunctions and disjunctions of
literals. Inductively:
\begin{enumerate}
\item A literal~\zref{prop-000Q} is in negation normal form;
\item If $\varphi$ and $\psi$ are in negation normal form, then so it
  $\varphi\land\psi$ and $\varphi\lor\psi$;
\item We nominally accept $\verum$ and $\falsum$ as ``degenerate'' cases
  of negation normal form.
\end{enumerate}
\end{definition}

\begin{node}[Transforming to NNF]\label{prop-000R}%
We can transform a formula into negation normal form by eliminating
``$\implies$'' and ``$\iff$'' using
\begin{subequations}
\begin{equation}
(A\implies B) \iff ((\neg A)\lor B),
\end{equation}
and
\begin{equation}
(A\iff B)\iff((A\lor\neg B)\land((\neg A)\lor B)).
\end{equation}
\end{subequations}
We can use De Morgan laws to simplify negated conjunctions and
disjunctions, and ``pull negations down to the literals'':
\begin{subequations}
  \begin{align}
    \neg(A\land B) &\iff (\neg A)\lor(\neg B)\\
    \neg(A\lor B) &\iff (\neg A)\land(\neg B)\\
    \neg(\neg A) &\iff A
\end{align}
\end{subequations}
In \SML, we could write a function transforming any \verb|Prop|
instance~\zref{prop-000G} into negation normal form (using some
optimizations) as something like:
\begin{sml}
(* nnf : Prop -> Prop *)
fun nnf (And(A,B)) = And (nnf A, nnf B)
  | nnf (Or(A,B)) = Or(nnf A, nnf B)
  | nnf (Implies(A,B)) = Or(nnf(Not A), nnf B)
  | nnf (Iff(A,B)) = Or(And(nnf A, nnf B),
                        And(nnf(Not A), nnf(Not B)))
  | nnf (Not (Not A)) = nnf A
  | nnf (Not (And (A, B))) = Or(nnf(Not A),nnf(Not B))
  | nnf (Not (Implies (A,B))) = And(nnf A, nnf(Not B))
  | nnf (Not (Iff (A,B))) = Or(And(nnf A, nnf(Not B)),
                               And(nnf(Not A), nnf B))
  | nnf (fm as _) = fm;
\end{sml}
\end{node}

\begin{definition}\label{prop-000S}%
A proposition is in \define{Disjunctive Normal Form} if it is the
disjunction of conjuncts, i.e., when it is of the form
\begin{subequations}
\begin{equation}
\varphi = D_{1}\lor D_{2}\lor\dots\lor D_{m}
\end{equation}
where each disjunct $D_{i}$ is of the form
\begin{equation}
D_{i} = \ell_{i_{1}}\land\ell_{i_{2}}\land\dots\land\ell_{i_{n_{i}}}
\end{equation}
\end{subequations}
(where each $\ell_{\star}$ is a literal~\zref{prop-000Q}).
\begin{theorem}\label{prop-000T}%
If a proposition is in disjunctive normal form, then it is in negation
normal form.
\end{theorem}
\end{definition}

\begin{definition}\label{prop-000U}%
A proposition is in \define{Conjunctive Normal Form} if it is the
conjunction of disjunctions of literals, i.e., if it is of the form
\begin{subequations}
\begin{equation}
C_{1}\land C_{2}\land\dots\land C_{m}
\end{equation}
where each conjunct $C_{i}$ is of the form
\begin{equation}
\ell_{i_{1}}\lor\ell_{i_{2}}\lor\dots\lor\ell_{i_{n_{i}}},
\end{equation}
and each $\ell_{i_{j}}$ is a literal~\zref{prop-000Q}.
\end{subequations}
\begin{theorem}\label{prop-000V}%
If a proposition is in conjunctive normal form, then it is in negation
normal form.
\end{theorem}
\end{definition}

\begin{definition}\label{prop-000W}%
Let $\varphi$ be a proposition.
We say a proposition $\psi$ is $\varphi$ in \define{Definitional Conjunctive Normal Form}
(or ``\textit{Definitional CNF}\,'' for short) if
$\psi$ is equisatisfiable as $\varphi$ (i.e., $\psi$ is satisfiable if
and only if $\varphi$ is satisfiable) and $\psi$ is obtained by finitely
many transformations, each of which introduce a ``fresh'' propositional
variable $X$ which replaces all instances of some subproposition
$\alpha$, and we conjunct onto it $X\iff\alpha$. There are a great many
variations of the procedure.

\begin{node}\label{prop-000X}%
It appears the first time the \emph{phrase} ``definitional CNF'' was
used may be found in Beckert and Posegga~\cite{beckert1994lean}. The
idea may be traced back to Tsetin~\cite{Tseitin1983}.
\end{node}
\end{definition}
\end{node}

